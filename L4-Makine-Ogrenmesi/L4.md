### Machine Learning (Makine Öğrenmesi)

---
#### Basic Concepts (Temel Kavramlar)

**Makine Öğrenmesi Nedir?** 

Bilgisayarların insanlara benzer şekilde öğrenmesini sağlamak maksadıyla
çeşitli algoritma ve tekiklerin geliştirilmesi için çalışılan
bilimsel çalışma alanıdır.

**Değişken Türleri (Variable Types)**

- Sayısal Değişkenler
- Kategorik Değişkenler (Nominal, Ordinal)
- Bağımlı Değişken (target, dependent, output, response): İncelenen değişkendir.
- Bağımsız Değişken (feature, independent, input, column, predictor, explanatory): Bağımlı değişkene etki ettiğini, 
onu oluşturduğunu varsaydığımız değişkendir.

> Sayısal bir bağımlı değişken üzerine çalışılıyorsa **regresyon** problemi, 
kategorik bir bağımlı değişken üzerinde çalışılıyorsa **sınıfladırma** problemidir.

**Öğrenme Türleri (Learning Types)**

Makine öğrenmesi üç tür öğrenme türü üzerinde gerçekleştirilir.

1) **Denetimli Öğrenme (Supervised Learning)**: Bağımlı (target) bir değişken varsa ve label olarak veri setide bulunuyorsa denetimli öğrenme
gerçekleşir.

2) **Denetimsiz Öğrenme (Unsupervised Learning)**: Bağımlı (target) bir değişken yoksa (label olarak veri setinde bulunmuyorsa) denetimsiz öğrenme
gerçekleşir.

3) **Pekiştirmeli Öğrenme (Reinforcement Learning)**: Deneme yanılma yoluyla pekiştire pekiştire öğrenme işlemidir.

**Problem Türleri (Problem Types)**

- **Regresyon problemlerinde** bağımlı değişken sayısaldır.
- **Sınıflandırma problemlerinde** bağımlı değişken kategoriktir.

> Algoritmalar numeric formatta bir veri seti ister. Bu yüzden kategorik veriler de
algoritmalarda kullanılırken önce numeric forma encode edilir.

**Model Doğrulama Yöntemleri (Model Validation)**

- Holdout Yöntemi (Sınama Seti Yöntemi): Veri seti ikiye bölünür.
Orijinal Veri Seti (Eğitim Seti + Test Seti)
- K-Katlı Çapraz Doğrulama (K Fold Cross Validation)
Holdout Yöntemi'nde küçük veri setlerinde oluşabilecek bölünme hatalarından dolayı açığa çıkmıştır.
K-katlı çağraz doğrulama iki şekilde uygulanabilir: orijinal veri setinde ya da
sadece eğitim setide cross validation uygulanarak. Burada sadece hatalara bakılmayacak aynı zamanda hiperparametre optimizasyonu için de kullanılacak.

**Yanlılık-Varyans Değiş Tokuşu (Bias-Variance Tradeoff)**

- **Underfitting (Yüksek Yanlılık)**: Veriler arası örüntüyü öğrenme gerçekleşmemiş. Bazı verilere yalılık yüksek olduğu gibi,
örüntüyü öğrenmemesinden kaynaklı düşük varyansa sahiptir. Genellenebilirlik yeteneği kazandırılamamıştır.

- **Doğru Model (Düşük Yanlılık, Düşük Varyans)**: Veriler arasındaki örüntü öğrenilmiştir.

- **Overfitting (Yüksek Varyans)**: Modelin veriyi öğrenmesi ezberlemesidir. 
Amacımız veriyi öğrenmesi değil verideki örüntüyü öğrenmesi beklenir.

>**Overfitting yani aşırı öğrenme nasıl engellenebilir?**
 Eğitim seti ve test setinin model karmaşıklığına (x ekseni) bağlı tahmin hatasındaki (y ekseni) değişikliğine bakarak anlaşılabilir. 
 Eğitim seti ve test setinin değer olarak ayrılmaya başladığı optimum model karmaşıklığı noktasında aşırı öğrenme başlamıştır diyebiliriz.
Bu optimum noktada iterasyon sayısı gibi değişkenleri durdurursak aşırı öğrenmenin önüne geçebilir.

Model karmaşıklığına örnekler:
- Lineer yöntemlerde üstel ifadelerin eklenmesi örnek verilebilir. 
- Ağaç yöntemlerinde dallanma karmaşıklığı arttırır.

---
#### Linear Regression (Doğrusal Regresyon) 

**Amaç:** Bağımlı (y) ve bağımsız (x) değişken/değişkenler arasındaki ilişkiyi doğrusal olarak modellemektedir.

b (bias) -> Sapma sabiti

w (ağırlık) -> değişkenlerin nasıl etkilediğini gösteren ağırlıklar (pozitif ya da negatif)

**Ağırlıklar nasıl bulunur?** Gerçek değerler ile tahmin edilen değerler arasındaki
farkların karelerinin toplamını/ortalamasını minimum yapabilecek b ve w değerlerini bularak.

**Regresyon Modellerinde Başarı Değerlendirme**

- MSE (Ne kadar **küçükse** o kadar iyidir): Tahminin ortalama hatasını gösterir.

MSE = (Gerçek değer ile tahmin edilen değerlerin farkının kareleri toplamı)/gözlem sayısı

> Tahmin edilen değerler ile gerçek değerlerin farkı negatif gelebilir. 
Toplama esnasında + ve - değerlerin 0 sonucunu verebilme ihtimaline karşın MSE'de kareleri alınmaktadır.

- RMSE: MSE'nin karekökü alınır.

- MAE: (Gerçek değerler ile tahmin edilen değerlerin farklarının mutlak değerlerinin toplamı)/gözlem sayısı

**Parametrelerin Tahmin Edilmesi (Ağırlıkların Bulunması)**

Amaç: Hata oranının en düşük olmasını sağlayan katsayıların (b ve w) bulunmasıdır.

- **Analitik Çözüm:** Normal Denklemler Yöntemi (En Küçük Kareler Yöntemi)
- **Optimizasyon Çözümü:** Gradient Descent

Gradient Descent Nedir ?

- Gradyanın negatifi olarak tanımlanan 'en dik iniş' yönünde iteratif olarak parametre
değerlerini güncelleyerek ilgili fonksiyonun minimum değerini verebilecek parametreleri bulur.

- Bir optimizasyon yöntemidir. Cost (e.g. MSE) fonksiyonunu minimize edebilecek parametreleri bulmak için kullanır.

> İlgili fonksiyonun ilgili parametreye göre kısmi türevi alınır. Bu türev fonksiyonun maksimum artış yönünü verir. Bu artış yönünün tersine belli bir büyüklükte (alfa) giderek parametrede değişiklik yapar. 
Böylece hatanın azalmasını sağlar. (Update Rule - Learning Rate)

Uygulama:

`linear_regression.py`

---
#### Logistic Regression (Lojistik Regresyon)

Amaç: Sınıflandırma problemi için bağımlı ve bağımsız değişkenler arasındaki ilişkiyi 
doğrusal olarak modellemektir.

- Doğrusal regresyondan gelen değer sigmoid fonksiyonundan geçirilir (değerler 0 - 1 arasına dönüştürülmüş olacak). 

Nasıl gerçekleştirilir ?

Gerçek değerler ile tahmin edilen değerler arasındaki farklara ilişkin Log Loss (MSE gibi)  değerini minimum yapabilecek ağırlıkları bularak işlem gerçekleştirilecek.


**Sınıflandırma Modellerinde Başarı Değerlendirme**

- Accuracy (Ne kadar **yüksekse** o kadar iyidir): Doğru sınıflandırma oranı

Confusion Matrix:

Yatay -> Tahmin edilen sınıf 
Dikey -> Gerçek sınıf

|           | Sınıf = 1           | Sınıf = 0           |
|---|---|---|
| Sınıf = 1 | True Positive (TP)  | False Negative (FN) |
| Sınıf = 0 | False Positive (FP) | True Negative  (TN) | 

**Accuracy:** Doğru sınıflandırma oranıdır. **(TP+TN)/(TP+TN+FP+FN)**
- Veri setinde sınıflar dengeli ise accuracy kullanılabilir. Dengeli değilse reccall ve precision değerlerine bakılmalıdır.

**Precision:** Pozitif sınıf (1) tahminlerinin başarı oranıdır. **TP/(TP+FP)**
- Dolandırıcı olarak tahmin edilenlerin ne kadarı doğru onu ifade eder. (1. Tip Hata)

**Recall:** Pozitif sınıfın (1) doğru tahmin edilme oranıdır. **TP/(TP+FN)**
- Dolandırıcılık işlemlerinin ne kadarının doğru tahmin edildiğini ifade eder. (2. Tip Hata)

**F1 SCORE:** 2 * (Precision * Recall)/(Precision + Recall)
- Precision ve Recall değerlerinin harmonik ortalamasıdır. İki değerin de önemli olması hasebiyle böyle bir score ortaya çıkmıştır.

**Classification Threshold**: 0-1 arasına indirgenen değerler bu eşik seviyesinin altında ise 0, üstündeyse 1'dir.

**ROC Curve (Receiver Operating Characteristic Curve)**

y -> True Positive Rate
x -> False Positive Rate

**Area Under Curve (AUC):** 
- ROC eğrisinin tek bir sayısal değer ile ifade edilişidir. 
- ROC eğrisi altında kalan alandır.
- AUC, tüm olası sınıflandırma eşikleri için toplu bir performans ölçüsüdür.

**LOF Loss:** Bir başarı metriğidir, hiper parametre optimizasyonu için kullanılır.

Entropi: Çeşitliliktir. Veri setinin çeşitliliğini gösterir. Bu değerin düşük olması istenir.


---
- K-Nearest Neighbors / KNN (K-En Yakın Komşu)
- Classification & Regression Tree / CART (Sınıflandırma ve Regresyon Ağacı)
- Advanced Tree Methods (Gelişmiş Ağaç Yöntemleri)
- Imbalanced Datasets (Dengesiz Veri Setleri)
- Unsupervised Learning (Denetimsiz Öğrenme)
- Machine Learning Pipeline (Makine Öğrenmesi Boru Hattı)
- **Projects**